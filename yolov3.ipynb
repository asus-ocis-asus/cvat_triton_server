{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d13544ad",
   "metadata": {},
   "source": [
    "# Cvat auto-labeling for YoloV3 and YoloV4 \n",
    "\n",
    "### In this notebook, it will show you how cvat auto-labeling for YoloV3 or YoloV4 works with AI-Maker inference. It depends on environment variable 'YOLO_VER' you passed to the inference to create YoloV3 or YoloV4 inference environment. You can reference templates we created for YoloV3 and YoloV4 inferences. We use YoloV3 as example in this notebook.\n",
    "\n",
    "When the yolov3 inference creates, it will execute 'run.sh' at workdir \"/opt/tensorrtserver\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3185670a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!cat run.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bbcaca",
   "metadata": {},
   "source": [
    "This script will first check inference environment (CPU or GPU) and export to ENV as later usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3624bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gpu_count=$(python3 check_env.py)\n",
    "if [ $gpu_count > 0 ]\n",
    "then\n",
    "    export INFERENCE_DEVICE=GPU\n",
    "else\n",
    "    export INFERENCE_DEVICE=CPU\n",
    "fi\n",
    "\n",
    "echo $INFERENCE_DEVICE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a7d85f",
   "metadata": {},
   "source": [
    "Base on ENV \"MODEL\" to run corresponding part of script. In this case, MODEL is \"YOLO\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6418e7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo $MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9102b3",
   "metadata": {},
   "source": [
    "Convert yolov3 weights from model management to onnx format according to environment variables defined in yolov3 template. You can check these environment variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a57fde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!echo $CONFIG_FILE_PATH, $WEIGHTS_FILE_PATH, $LABEL_FILE_PATH, $YOLO_VER, $CONFIDENCE_THRESH, $NMS_THRESH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f050fe",
   "metadata": {},
   "source": [
    "Run yolo_to_onnx.py to convert yolov3 weights to onnx format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e2b178",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 yolo/yolo_onnx/yolo_to_onnx.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5042bcf1",
   "metadata": {},
   "source": [
    "Converted onnx model will be found at /models/yolov3/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fc7b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -al /models/yolov3/1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1fa84c",
   "metadata": {},
   "source": [
    "\n",
    "Set model_name from ENV \"YOLO_VER\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e59ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "if [ -v YOLO_VER ] && [ $YOLO_VER = 'V4' ]\n",
    "then\n",
    "    model_name=\"yolov4\"\n",
    "else\n",
    "    model_name=\"yolov3\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d9d1f6",
   "metadata": {},
   "source": [
    "Get anchors defined in yolov3 config file and export to ENV as later usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc89fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "anchors=$(python3 yolo/yolo_onnx/get_anchors.py)\n",
    "export YOLO_ANCHORS=$anchors\n",
    "echo $YOLO_ANCHORS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0025b78",
   "metadata": {},
   "source": [
    "Create model config file by \"build_config.py\". See usage by argument \"--help\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dcbf49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python3 build_config.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782ca638",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 build_config.py -m $model_name --max-batch-size 0 -f onnxruntime_onnx -d $INFERENCE_DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8ad86d",
   "metadata": {},
   "source": [
    "Model config file path is /models/{$model_name}/config.pbtxt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd64379d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!cat /models/yolov3/config.pbtxt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bcd986",
   "metadata": {},
   "source": [
    "We use Nvidia Triton inference server 19.10 as model inference engine, so we need to prepare model config file and put it at /models/yolov3 with model file as below directory structure. About Nvidia Triton inference server, you can reference [Triton Inference Server](https://github.com/triton-inference-server/server/tree/v1.7.0) for more informations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b437adc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!ls -R /models/yolov3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f92997b",
   "metadata": {},
   "source": [
    "Start triton inference server for model infernece, inference server will run in background and ready to accept inference requests by port 8000 for http and port 8001 for grpc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75a53b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "subprocess.Popen([\"trtserver\", \"--model-repository=/models\", \"--strict-model-config=false\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299e1e95",
   "metadata": {},
   "source": [
    "Check triton server status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77828732",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ps aux | grep trtserver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17fe043",
   "metadata": {},
   "source": [
    "Check yolov3 model status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29f063c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!curl http://localhost:8000/api/status/yolov3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8909b9f0",
   "metadata": {},
   "source": [
    "Implement custom api for yolov3.\n",
    "Two functions \"cvat_invoke\" and \"cvat_info\" of api.py need to be customize by user. This is yolov3 sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efdc18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat yolo/api.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa1d6d3",
   "metadata": {},
   "source": [
    "Function \"cvat_invoke\" will accept http post request from cvat server and return yolov3 inference results. Post data will be json format and be a base64 image for this yolov3 example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62d2210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvat_invoke(post_json):\n",
    "    url = \"localhost:8001\"\n",
    "    protocol = \"grpc\"\n",
    "    protocol = ProtocolType.from_str(protocol)\n",
    "    if os.environ['YOLO_VER'] == 'V4':\n",
    "        model_name = \"yolov4\"\n",
    "    else:\n",
    "        model_name = \"yolov3\"\n",
    "    input_name, output_names, output_shapes, c, h, w = parse_model(url, protocol, model_name, 1, False)\n",
    "    input_resolution_yolov3_HW = (h, w)\n",
    "    preprocessor = PreprocessYOLO(input_resolution_yolov3_HW)\n",
    "    image_raw, image = preprocessor.process(post_json[\"image\"])\n",
    "    shape_orig_WH = image_raw.size\n",
    "\n",
    "    trt_outputs = []\n",
    "    ctx = InferContext(url, protocol, model_name, 1, False, 0, False)\n",
    "    input_batch = [image]\n",
    "\n",
    "    output_dict = {\n",
    "        output_name: InferContext.ResultFormat.RAW\n",
    "        for output_name in output_names\n",
    "    }\n",
    "\n",
    "    response = ctx.run(\n",
    "        {input_name: input_batch}, output_dict, len(input_batch))\n",
    "\n",
    "    trt_outputs = [response[output][0] for output in sorted(response.keys())]\n",
    "    trt_outputs = [output.reshape(shape) for output, shape in zip(trt_outputs, output_shapes)]\n",
    "    anchors = get_anchors()\n",
    "    if os.environ['YOLO_VER'] == 'V4':\n",
    "        yolo_masks = [(0, 1, 2), (3, 4, 5), (6, 7, 8)]\n",
    "    else:\n",
    "        yolo_masks = [(6, 7, 8), (3, 4, 5), (0, 1, 2)]\n",
    "    if os.environ.get('CONFIDENCE_THRESH'):\n",
    "        obj_threshold = float(os.environ['CONFIDENCE_THRESH'])\n",
    "    else:\n",
    "        obj_threshold = 0.3\n",
    "    if os.environ.get('NMS_THRESH'):\n",
    "        nms_threshold = float(os.environ['NMS_THRESH'])\n",
    "    else:\n",
    "        nms_threshold = 0.5\n",
    "    postprocessor_args = {\"yolo_masks\": yolo_masks,\n",
    "                          \"yolo_anchors\": anchors,\n",
    "                          \"obj_threshold\": obj_threshold,\n",
    "                          \"nms_threshold\": nms_threshold,\n",
    "                          \"yolo_input_resolution\": input_resolution_yolov3_HW}\n",
    "\n",
    "    postprocessor = PostprocessYOLO(**postprocessor_args)\n",
    "\n",
    "    boxes, classes, scores = postprocessor.process(trt_outputs, (shape_orig_WH))\n",
    "    results = []\n",
    "    if len(boxes) > 0 and len(classes) > 0 and len(scores) > 0:\n",
    "        for box, score, category in zip(boxes, scores, classes):\n",
    "            x_coord, y_coord, width, height = box\n",
    "            left = int(max(0, np.floor(x_coord + 0.5).astype(int)))\n",
    "            top = int(max(0, np.floor(y_coord + 0.5).astype(int)))\n",
    "            right = int(min(image_raw.width, np.floor(x_coord + width + 0.5).astype(int)))\n",
    "            bottom = int(min(image_raw.height, np.floor(y_coord + height + 0.5).astype(int)))\n",
    "            results.append({\"label\": ALL_CATEGORIES[category], \"points\": [left, top, right, bottom], \"type\": \"rectangle\", \"attributes\": []})\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d072588b",
   "metadata": {},
   "source": [
    "Function \"cvat_info\" will return display informations for cvat server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c3a7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvat_info():\n",
    "    resp = {\"framework\": \"yolov3\", \"spec\": ALL_CATEGORIES, \"type\": \"detector\", \"description\": \"Object detetion via Yolov3\"}\n",
    "    return resp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819ccb2f",
   "metadata": {},
   "source": [
    "Install custom package if your customizations are ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa77268",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!python3 yolo/setup.py install"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bdae20",
   "metadata": {},
   "source": [
    "Run Flask http server with Waitress to serve inference request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa33446",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "subprocess.Popen([\"waitress-serve\", \"--call\", \"--port\", \"9999\", \"webapp:create_app\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bac1346",
   "metadata": {},
   "source": [
    "Check waitress status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a23778c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ps aux | grep waitress"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5090ee",
   "metadata": {},
   "source": [
    "Now your cvat auto-labeling for yolov3 at AI-Maker is ready to go."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
